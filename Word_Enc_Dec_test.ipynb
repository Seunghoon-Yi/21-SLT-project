{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c74139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import torch\n",
    "from torch import nn, tensor\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e586e0fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "'''fasttext.util.download_model('de', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.de.300.bin')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a31378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7096, 7) (642, 7) (519, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    und nun die wettervorhersage für morgen donner...\n",
       "1    mancherorts regnet es auch länger und ergiebig...\n",
       "2    im nordwesten bleibt es heute nacht meist troc...\n",
       "3    auch am tag gibt es verbreitet zum teil kräfti...\n",
       "4    größere wolkenlücken finden sich vor allem im ...\n",
       "Name: translation, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_dir = './PHOENIX-2014-T.train.corpus.csv'\n",
    "test_text_dir  = './PHOENIX-2014-T.test.corpus.csv'\n",
    "dev_text_dir   = './PHOENIX-2014-T.dev.corpus.csv'\n",
    "train_text = pd.read_csv(train_text_dir,delimiter='|' )\n",
    "test_text  = pd.read_csv(test_text_dir,delimiter='|' )\n",
    "dev_text   = pd.read_csv(dev_text_dir,delimiter='|' )\n",
    "\n",
    "# print first 5 rows of training dataset text.\n",
    "print(train_text.shape, test_text.shape, dev_text.shape)\n",
    "train_text.head(5)['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7721a001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example string : \n",
      " und nun die wettervorhersage für morgen donnerstag den zwölften august\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nword_id = [ft.get_word_id(i) for i in example_seq.split(\\' \\')]\\nprint(word_id)\\n\\nmax_length = 56\\n#from keras.preprocessing import sequence\\n#padded = sequence.pad_sequences(example_seq, maxlen = max_length)\\n#padded = [word_id.append(0) for i in range(max_length-len(word_id))]\\nfor i in range(max_length-len(word_id)):\\n    if len(word_id)<=max_length:\\n        word_id.append(0)\\nprint(\"Padded string\")\\nprint(word_id)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = train_text['translation'].tolist()\n",
    "test_list  = test_text['translation'].tolist()\n",
    "dev_list   = dev_text['translation'].tolist()\n",
    "\n",
    "example_seq = train_list[0]\n",
    "print(\"Example string : \\n\",example_seq)\n",
    "'''\n",
    "word_id = [ft.get_word_id(i) for i in example_seq.split(' ')]\n",
    "print(word_id)\n",
    "\n",
    "max_length = 56\n",
    "#from keras.preprocessing import sequence\n",
    "#padded = sequence.pad_sequences(example_seq, maxlen = max_length)\n",
    "#padded = [word_id.append(0) for i in range(max_length-len(word_id))]\n",
    "for i in range(max_length-len(word_id)):\n",
    "    if len(word_id)<=max_length:\n",
    "        word_id.append(0)\n",
    "print(\"Padded string\")\n",
    "print(word_id)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e89de5",
   "metadata": {},
   "source": [
    "#### 0. Use BPEmb instead of fasttext. #### <br>\n",
    "(since we do not need heavy n-gram models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3ef9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "bpemb_de = BPEmb(lang=\"de\", vs = 200000, dim = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a33656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given string :  und nun die wettervorhersage für morgen donnerstag den zwölften august \n",
      "\n",
      "Byte pair encoded  :  ['<s>', '▁und', '▁nun', '▁die', '▁wetter', 'vorhersage', '▁für', '▁morgen', '▁donnerstag', '▁den', '▁zwölften', '▁august', '</s>'] \n",
      "\n",
      "encoded IDs with BOS EOS :  [1, 43, 1667, 31, 6478, 81915, 137, 5702, 28908, 91, 32966, 897, 2]\n",
      "Encoded vector with BOS EOS \n",
      " [[ 0.182308 -0.126659 -0.241143 ...  0.318721 -0.168438 -0.062049]\n",
      " [-0.120836 -0.031391  0.086993 ...  0.211641 -0.269986  0.115533]\n",
      " [-0.205385 -0.032322 -0.212051 ...  0.258928 -0.616859 -0.064941]\n",
      " ...\n",
      " [ 0.428949 -0.048978  0.039888 ...  0.013891  0.09221  -0.006973]\n",
      " [ 0.218135 -0.001797 -0.290565 ...  0.433684 -0.836161 -0.296046]\n",
      " [-0.351755  0.015497  0.048089 ... -0.060799 -0.559905 -0.096867]]\n",
      "decoded :  und nun die wettervorhersage für morgen donnerstag den zwölften august\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "teststring = train_list[0]\n",
    "print(\"given string : \", teststring,'\\n')\n",
    "testBPE = bpemb_de.encode_with_bos_eos(teststring)\n",
    "print(\"Byte pair encoded  : \", testBPE,'\\n')\n",
    "\n",
    "ids = bpemb_de.encode_ids_with_bos_eos(teststring)\n",
    "print(\"encoded IDs with BOS EOS : \", ids)\n",
    "\n",
    "vecs = bpemb_de.vectors[ids]\n",
    "print(\"Encoded vector with BOS EOS \\n\",vecs)\n",
    "\n",
    "decoded = bpemb_de.decode(testBPE)\n",
    "print(\"decoded : \", decoded)\n",
    "\n",
    "print(type(vecs))\n",
    "testvec = vecs.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8e9751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67]\n",
      "(200000, 300) (13, 300) (200000,) (13,)\n",
      "[6.7861857 3.9222107 3.6583624 4.9993978 5.829991  5.3909874 4.894021\n",
      " 5.3435245 6.156014  5.620022 ]\n",
      "[[26.61685   23.083723  29.130737  26.94188   45.018665  41.945312\n",
      "  32.13576   39.217175  39.071564  28.290976  38.90293   36.355198\n",
      "  24.826326 ]\n",
      " [15.383737  13.341696  16.836687  15.571593  26.01943   24.243126\n",
      "  18.573502  22.666344  22.582186  16.35133   22.48472   21.012207\n",
      "  14.348868 ]\n",
      " [14.348868  12.444196  15.704079  14.524088  24.269096  22.612284\n",
      "  17.324057  21.141573  21.063074  15.251371  20.972166  19.598711\n",
      "  13.3836155]\n",
      " [19.608692  17.005829  21.460678  19.84814   33.165348  30.901203\n",
      "  23.674486  28.891378  28.784105  20.842022  28.659872  26.782953\n",
      "  18.289608 ]\n",
      " [22.866453  19.831154  25.026125  23.145683  38.675392  36.035088\n",
      "  27.607733  33.691353  33.566257  24.304688  33.421387  31.232635\n",
      "  21.328218 ]\n",
      " [21.144588  18.33785   23.141636  21.402794  35.763103  33.321613\n",
      "  25.528845  31.154364  31.038689  22.474524  30.904726  28.88079\n",
      "  19.722185 ]\n",
      " [19.195381  16.647383  21.008331  19.429785  32.466293  30.24987\n",
      "  23.175478  28.28241   28.177397  20.402718  28.055784  26.218426\n",
      "  17.904102 ]\n",
      " [20.95843   18.176403  22.937895  21.214361  35.44824   33.028244\n",
      "  25.304087  30.880077  30.765419  22.276655  30.632635  28.62652\n",
      "  19.54855  ]\n",
      " [24.145184  20.940147  26.425629  24.440031  40.83819   38.05023\n",
      "  29.151604  35.57543   35.44334   25.663847  35.290367  32.979218\n",
      "  22.52093  ]\n",
      " [22.04291   19.116928  24.124802  22.312084  37.282486  34.73727\n",
      "  26.61343   32.477947  32.357357  23.429346  32.2177    30.107782\n",
      "  20.560076 ]] (200000, 13)\n"
     ]
    }
   ],
   "source": [
    "# we'll pad tokens with '*'\n",
    "print(bpemb_de.encode_ids('*'))\n",
    "totalWV    = bpemb_de.vectors\n",
    "totalWV_VS = np.sqrt(np.sum(totalWV**2, axis = 1))\n",
    "testvec_VS = np.sqrt(np.sum(vecs**2, axis = 1))\n",
    "print(totalWV.shape, vecs.shape, totalWV_VS.shape, testvec_VS.shape)\n",
    "print(totalWV_VS[:10])\n",
    "norm_mat = np.outer(totalWV_VS, testvec_VS)\n",
    "print(norm_mat[:10], norm_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d683b1",
   "metadata": {},
   "source": [
    "**Encoding words are automatic, but decoding must(not a must, but else consumes >15Gb of RAM) be manual.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65df5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1    43  1667    31  6478 81915   137  5702 28908    91 32966   897\n",
      "     2] (13,)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "def find_similar_vec(vector_arr):\n",
    "    IDs = []\n",
    "    score     = totalWV.dot(vector_arr.T)\n",
    "    vector_VS = np.sqrt(np.sum(vector_arr**2, axis = 1))\n",
    "    norm_mtx  = np.outer(totalWV_VS, vector_VS)\n",
    "    score /= norm_mtx\n",
    "    IDs = np.argmax(score, axis = 0)\n",
    "    \n",
    "    IDs[0], IDs[-1] = 1, 2\n",
    "    return IDs\n",
    "\n",
    "similar_ids = find_similar_vec(vecs)\n",
    "print(similar_ids, similar_ids.shape)\n",
    "print(similar_ids == ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd525b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = nn.Embedding.from_pretrained(tensor(bpemb_de.vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b209deb",
   "metadata": {},
   "source": [
    "**5/12** :  We want to make a consistant embedding - that is, equal length emb. through all text datas - for our dataset. Here I represent 4 steps to do preprocessing. <br><br>\n",
    "#### 1. Extract example string array from textfile, and convert them to ASCII format ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13f59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "526d8522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['regen und schnee lassen an den alpen in der nacht nach im norden und nordosten fallen hier und da schauer sonst ist das klar', 'am donnerstag regen in der nordhälfte in der südhälfte mal sonne mal wolken ähnliches wetter dann auch am freitag', 'vom nordmeer zieht ein kräftiges tief heran und bringt uns ab den morgenstunden heftige schneefälle zum teil auch gefrierenden regen', 'sonnig geht es auch ins wochenende samstag ein herrlicher tag mit temperaturen bis siebzehn grad hier im westen', 'deutschland liegt morgen unter hochdruckeinfluss der die wolken weitgehend vertreibt', 'am sonntag im nordwesten eine mischung aus sonne und wolken mit einigen zum teil gewittrigen schauern', 'örtlich schauer oder gewitter die heftig sein können', 'in den nächsten tagen geht es auf jeden fall winterlich weiter immer wieder mal mit etwas schnee', 'und zum wochenende wird es dann sogar wieder ein bisschen kälter', 'auch morgen erwartet uns eine ruhige herbstmischung aus hochnebel wolken und sonne']\n"
     ]
    }
   ],
   "source": [
    "# train_text.head(5)                                                     # This will show our annota\n",
    "\n",
    "examplestring = [i for i in test_text.head(10)['translation'].tolist()]\n",
    "print(examplestring)                                                    # Show strings over row 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b488c200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> regen und schnee lassen an den alpen in der nacht nach im norden und nordosten fallen hier und da schauer sonst ist das klar </s>\n",
      "<s> am donnerstag regen in der nordhälfte in der südhälfte mal sonne mal wolken ähnliches wetter dann auch am freitag </s>\n",
      "<s> vom nordmeer zieht ein kräftiges tief heran und bringt uns ab den morgenstunden heftige schneefälle zum teil auch gefrierenden regen </s>\n",
      "<s> sonnig geht es auch ins wochenende samstag ein herrlicher tag mit temperaturen bis siebzehn grad hier im westen </s>\n",
      "<s> deutschland liegt morgen unter hochdruckeinfluss der die wolken weitgehend vertreibt </s>\n",
      "<s> am sonntag im nordwesten eine mischung aus sonne und wolken mit einigen zum teil gewittrigen schauern </s>\n",
      "<s> örtlich schauer oder gewitter die heftig sein können </s>\n",
      "<s> in den nächsten tagen geht es auf jeden fall winterlich weiter immer wieder mal mit etwas schnee </s>\n",
      "<s> und zum wochenende wird es dann sogar wieder ein bisschen kälter </s>\n",
      "<s> auch morgen erwartet uns eine ruhige herbstmischung aus hochnebel wolken und sonne </s>\n"
     ]
    }
   ],
   "source": [
    "def U2A(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "def preprocess(word):\n",
    "    #word = U2A(word.lower().strip())   # strip() method erases whitespace in either side of the sentence.\n",
    "    \n",
    "    word = word.strip()\n",
    "    word = '<s> ' + word + ' </s>'\n",
    "    \n",
    "    return word\n",
    "\n",
    "for sentence in examplestring:\n",
    "    processed_ = preprocess(sentence)\n",
    "    print(processed_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c8a987",
   "metadata": {},
   "source": [
    "#### 2. Now pad the sequences to max_length(maybe 55) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24fe7a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "# Check the maximum length\n",
    "max_len = 0\n",
    "for string in train_list:\n",
    "    string_ids = bpemb_de.encode_ids_with_bos_eos(string)\n",
    "    if max_len<=len(string_ids):\n",
    "        max_len = len(string_ids)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "927f9adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done :  0\n",
      "Done :  1\n",
      "Done :  2\n",
      "Done :  3\n",
      "Done :  4\n",
      "Done :  5\n",
      "Done :  6\n",
      "Done :  7\n",
      "Done :  8\n",
      "Done :  9\n",
      "Done :  10\n",
      "Done :  11\n",
      "Done :  12\n",
      "Done :  13\n",
      "Done :  14\n",
      "Done :  15\n",
      "Done :  16\n",
      "Done :  17\n",
      "Done :  18\n",
      "Done :  19\n",
      "Done :  20\n",
      "Done :  21\n",
      "Done :  22\n",
      "Done :  23\n",
      "Done :  24\n",
      "Done :  25\n",
      "Done :  26\n",
      "Done :  27\n",
      "Done :  28\n",
      "Done :  29\n",
      "Done :  30\n",
      "Done :  31\n",
      "Done :  32\n",
      "Done :  33\n",
      "Done :  34\n",
      "Done :  35\n",
      "Done :  36\n",
      "Done :  37\n",
      "Done :  38\n",
      "Done :  39\n",
      "Done :  40\n",
      "Done :  41\n",
      "Done :  42\n",
      "Done :  43\n",
      "Done :  44\n",
      "Done :  45\n",
      "Done :  46\n",
      "Done :  47\n",
      "Done :  48\n",
      "Done :  49\n",
      "Done :  50\n",
      "Done :  51\n",
      "Done :  52\n",
      "Done :  53\n",
      "Done :  54\n",
      "Done :  55\n",
      "Done :  56\n",
      "Done :  57\n",
      "Done :  58\n",
      "Done :  59\n",
      "Done :  60\n",
      "Done :  61\n",
      "Done :  62\n",
      "Done :  63\n",
      "Done :  64\n",
      "Done :  65\n",
      "Done :  66\n",
      "Done :  67\n",
      "Done :  68\n",
      "Done :  69\n",
      "Done :  70\n",
      "Done :  71\n",
      "Done :  72\n",
      "Done :  73\n",
      "Done :  74\n",
      "Done :  75\n",
      "Done :  76\n",
      "Done :  77\n",
      "Done :  78\n",
      "Done :  79\n",
      "Done :  80\n",
      "Done :  81\n",
      "Done :  82\n",
      "Done :  83\n",
      "Done :  84\n",
      "Done :  85\n",
      "Done :  86\n",
      "Done :  87\n",
      "Done :  88\n",
      "Done :  89\n",
      "Done :  90\n",
      "Done :  91\n",
      "Done :  92\n",
      "Done :  93\n",
      "Done :  94\n",
      "Done :  95\n",
      "Done :  96\n",
      "Done :  97\n",
      "Done :  98\n",
      "Done :  99\n",
      "Done :  100\n",
      "Done :  101\n",
      "Done :  102\n",
      "Done :  103\n",
      "Done :  104\n",
      "Done :  105\n",
      "Done :  106\n",
      "Done :  107\n",
      "Done :  108\n",
      "Done :  109\n",
      "Done :  110\n",
      "Done :  111\n",
      "Done :  112\n",
      "Done :  113\n",
      "Done :  114\n",
      "Done :  115\n",
      "Done :  116\n",
      "Done :  117\n",
      "Done :  118\n",
      "Done :  119\n",
      "Done :  120\n",
      "Done :  121\n",
      "Done :  122\n",
      "Done :  123\n",
      "Done :  124\n",
      "Done :  125\n",
      "Done :  126\n",
      "Done :  127\n",
      "Done :  128\n",
      "Done :  129\n",
      "Done :  130\n",
      "Done :  131\n",
      "Done :  132\n",
      "Done :  133\n",
      "Done :  134\n",
      "Done :  135\n",
      "Done :  136\n",
      "Done :  137\n",
      "Done :  138\n",
      "Done :  139\n",
      "Done :  140\n",
      "Done :  141\n",
      "Done :  142\n",
      "Done :  143\n",
      "Done :  144\n",
      "Done :  145\n",
      "Done :  146\n",
      "Done :  147\n",
      "Done :  148\n",
      "Done :  149\n",
      "Done :  150\n",
      "Done :  151\n",
      "Done :  152\n",
      "Done :  153\n",
      "Done :  154\n",
      "Done :  155\n",
      "Done :  156\n",
      "Done :  157\n",
      "Done :  158\n",
      "Done :  159\n",
      "Done :  160\n",
      "Done :  161\n",
      "Done :  162\n",
      "Done :  163\n",
      "Done :  164\n",
      "Done :  165\n",
      "Done :  166\n",
      "Done :  167\n",
      "Done :  168\n",
      "Done :  169\n",
      "Done :  170\n",
      "Done :  171\n",
      "Done :  172\n",
      "Done :  173\n",
      "Done :  174\n",
      "Done :  175\n",
      "Done :  176\n",
      "Done :  177\n",
      "Done :  178\n",
      "Done :  179\n",
      "Done :  180\n",
      "Done :  181\n",
      "Done :  182\n",
      "Done :  183\n",
      "Done :  184\n",
      "Done :  185\n",
      "Done :  186\n",
      "Done :  187\n",
      "Done :  188\n",
      "Done :  189\n",
      "Done :  190\n",
      "Done :  191\n",
      "Done :  192\n",
      "Done :  193\n",
      "Done :  194\n",
      "Done :  195\n",
      "Done :  196\n",
      "Done :  197\n",
      "Done :  198\n",
      "Done :  199\n",
      "Done :  200\n",
      "Done :  201\n",
      "Done :  202\n",
      "Done :  203\n",
      "Done :  204\n",
      "Done :  205\n",
      "Done :  206\n",
      "Done :  207\n",
      "Done :  208\n",
      "Done :  209\n",
      "Done :  210\n",
      "Done :  211\n",
      "Done :  212\n",
      "Done :  213\n",
      "Done :  214\n",
      "Done :  215\n",
      "Done :  216\n",
      "Done :  217\n",
      "Done :  218\n",
      "Done :  219\n",
      "Done :  220\n",
      "Done :  221\n",
      "Done :  222\n",
      "Done :  223\n",
      "Done :  224\n",
      "Done :  225\n",
      "Done :  226\n",
      "Done :  227\n",
      "Done :  228\n",
      "Done :  229\n",
      "Done :  230\n",
      "Done :  231\n",
      "Done :  232\n",
      "Done :  233\n",
      "Done :  234\n",
      "Done :  235\n",
      "Done :  236\n",
      "Done :  237\n",
      "Done :  238\n",
      "Done :  239\n",
      "Done :  240\n",
      "Done :  241\n",
      "Done :  242\n",
      "Done :  243\n",
      "Done :  244\n",
      "Done :  245\n",
      "Done :  246\n",
      "Done :  247\n",
      "Done :  248\n",
      "Done :  249\n",
      "Done :  250\n",
      "Done :  251\n",
      "Done :  252\n",
      "Done :  253\n",
      "Done :  254\n",
      "Done :  255\n",
      "Done :  256\n",
      "Done :  257\n",
      "Done :  258\n",
      "Done :  259\n",
      "Done :  260\n",
      "Done :  261\n",
      "Done :  262\n",
      "Done :  263\n",
      "Done :  264\n",
      "Done :  265\n",
      "Done :  266\n",
      "Done :  267\n",
      "Done :  268\n",
      "Done :  269\n",
      "Done :  270\n",
      "Done :  271\n",
      "Done :  272\n",
      "Done :  273\n",
      "Done :  274\n",
      "Done :  275\n",
      "Done :  276\n",
      "Done :  277\n",
      "Done :  278\n",
      "Done :  279\n",
      "Done :  280\n",
      "Done :  281\n",
      "Done :  282\n",
      "Done :  283\n",
      "Done :  284\n",
      "Done :  285\n",
      "Done :  286\n",
      "Done :  287\n",
      "Done :  288\n",
      "Done :  289\n",
      "Done :  290\n",
      "Done :  291\n",
      "Done :  292\n",
      "Done :  293\n",
      "Done :  294\n",
      "Done :  295\n",
      "Done :  296\n",
      "Done :  297\n",
      "Done :  298\n",
      "Done :  299\n",
      "Done :  300\n",
      "Done :  301\n",
      "Done :  302\n",
      "Done :  303\n",
      "Done :  304\n",
      "Done :  305\n",
      "Done :  306\n",
      "Done :  307\n",
      "Done :  308\n",
      "Done :  309\n",
      "Done :  310\n",
      "Done :  311\n",
      "Done :  312\n",
      "Done :  313\n",
      "Done :  314\n",
      "Done :  315\n",
      "Done :  316\n",
      "Done :  317\n",
      "Done :  318\n",
      "Done :  319\n",
      "Done :  320\n",
      "Done :  321\n",
      "Done :  322\n",
      "Done :  323\n",
      "Done :  324\n",
      "Done :  325\n",
      "Done :  326\n",
      "Done :  327\n",
      "Done :  328\n",
      "Done :  329\n",
      "Done :  330\n",
      "Done :  331\n",
      "Done :  332\n",
      "Done :  333\n",
      "Done :  334\n",
      "Done :  335\n",
      "Done :  336\n",
      "Done :  337\n",
      "Done :  338\n",
      "Done :  339\n",
      "Done :  340\n",
      "Done :  341\n",
      "Done :  342\n",
      "Done :  343\n",
      "Done :  344\n",
      "Done :  345\n",
      "Done :  346\n",
      "Done :  347\n",
      "Done :  348\n",
      "Done :  349\n",
      "Done :  350\n",
      "Done :  351\n",
      "Done :  352\n",
      "Done :  353\n",
      "Done :  354\n",
      "Done :  355\n",
      "Done :  356\n",
      "Done :  357\n",
      "Done :  358\n",
      "Done :  359\n",
      "Done :  360\n",
      "Done :  361\n",
      "Done :  362\n",
      "Done :  363\n",
      "Done :  364\n",
      "Done :  365\n",
      "Done :  366\n",
      "Done :  367\n",
      "Done :  368\n",
      "Done :  369\n",
      "Done :  370\n",
      "Done :  371\n",
      "Done :  372\n",
      "Done :  373\n",
      "Done :  374\n",
      "Done :  375\n",
      "Done :  376\n",
      "Done :  377\n",
      "Done :  378\n",
      "Done :  379\n",
      "Done :  380\n",
      "Done :  381\n",
      "Done :  382\n",
      "Done :  383\n",
      "Done :  384\n",
      "Done :  385\n",
      "Done :  386\n",
      "Done :  387\n",
      "Done :  388\n",
      "Done :  389\n",
      "Done :  390\n",
      "Done :  391\n",
      "Done :  392\n",
      "Done :  393\n",
      "Done :  394\n",
      "Done :  395\n",
      "Done :  396\n",
      "Done :  397\n",
      "Done :  398\n",
      "Done :  399\n",
      "Done :  400\n",
      "Done :  401\n",
      "Done :  402\n",
      "Done :  403\n",
      "Done :  404\n",
      "Done :  405\n",
      "Done :  406\n",
      "Done :  407\n",
      "Done :  408\n",
      "Done :  409\n",
      "Done :  410\n",
      "Done :  411\n",
      "Done :  412\n",
      "Done :  413\n",
      "Done :  414\n",
      "Done :  415\n",
      "Done :  416\n",
      "Done :  417\n",
      "Done :  418\n",
      "Done :  419\n",
      "Done :  420\n",
      "Done :  421\n",
      "Done :  422\n",
      "Done :  423\n",
      "Done :  424\n",
      "Done :  425\n",
      "Done :  426\n",
      "Done :  427\n",
      "Done :  428\n",
      "Done :  429\n",
      "Done :  430\n",
      "Done :  431\n",
      "Done :  432\n",
      "Done :  433\n",
      "Done :  434\n",
      "Done :  435\n",
      "Done :  436\n",
      "Done :  437\n",
      "Done :  438\n",
      "Done :  439\n",
      "Done :  440\n",
      "Done :  441\n",
      "Done :  442\n",
      "Done :  443\n",
      "Done :  444\n",
      "Done :  445\n",
      "Done :  446\n",
      "Done :  447\n",
      "Done :  448\n",
      "Done :  449\n",
      "Done :  450\n",
      "Done :  451\n",
      "Done :  452\n",
      "Done :  453\n",
      "Done :  454\n",
      "Done :  455\n",
      "Done :  456\n",
      "Done :  457\n",
      "Done :  458\n",
      "Done :  459\n",
      "Done :  460\n",
      "Done :  461\n",
      "Done :  462\n",
      "Done :  463\n",
      "Done :  464\n",
      "Done :  465\n",
      "Done :  466\n",
      "Done :  467\n",
      "Done :  468\n",
      "Done :  469\n",
      "Done :  470\n",
      "Done :  471\n",
      "Done :  472\n",
      "Done :  473\n",
      "Done :  474\n",
      "Done :  475\n",
      "Done :  476\n",
      "Done :  477\n",
      "Done :  478\n",
      "Done :  479\n",
      "Done :  480\n",
      "Done :  481\n",
      "Done :  482\n",
      "Done :  483\n",
      "Done :  484\n",
      "Done :  485\n",
      "Done :  486\n",
      "Done :  487\n",
      "Done :  488\n",
      "Done :  489\n",
      "Done :  490\n",
      "Done :  491\n",
      "Done :  492\n",
      "Done :  493\n",
      "Done :  494\n",
      "Done :  495\n",
      "Done :  496\n",
      "Done :  497\n",
      "Done :  498\n",
      "Done :  499\n",
      "Done :  500\n",
      "Done :  501\n",
      "Done :  502\n",
      "Done :  503\n",
      "Done :  504\n",
      "Done :  505\n",
      "Done :  506\n",
      "Done :  507\n",
      "Done :  508\n",
      "Done :  509\n",
      "Done :  510\n",
      "Done :  511\n",
      "Done :  512\n",
      "Done :  513\n",
      "Done :  514\n",
      "Done :  515\n",
      "Done :  516\n",
      "Done :  517\n",
      "Done :  518\n",
      "Done :  519\n",
      "Done :  520\n",
      "Done :  521\n",
      "Done :  522\n",
      "Done :  523\n",
      "Done :  524\n",
      "Done :  525\n",
      "Done :  526\n",
      "Done :  527\n",
      "Done :  528\n",
      "Done :  529\n",
      "Done :  530\n",
      "Done :  531\n",
      "Done :  532\n",
      "Done :  533\n",
      "Done :  534\n",
      "Done :  535\n",
      "Done :  536\n",
      "Done :  537\n",
      "Done :  538\n",
      "Done :  539\n",
      "Done :  540\n",
      "Done :  541\n",
      "Done :  542\n",
      "Done :  543\n",
      "Done :  544\n",
      "Done :  545\n",
      "Done :  546\n",
      "Done :  547\n",
      "Done :  548\n",
      "Done :  549\n",
      "Done :  550\n",
      "Done :  551\n",
      "Done :  552\n",
      "Done :  553\n",
      "Done :  554\n",
      "Done :  555\n",
      "Done :  556\n",
      "Done :  557\n",
      "Done :  558\n",
      "Done :  559\n",
      "Done :  560\n",
      "Done :  561\n",
      "Done :  562\n",
      "Done :  563\n",
      "Done :  564\n",
      "Done :  565\n",
      "Done :  566\n",
      "Done :  567\n",
      "Done :  568\n",
      "Done :  569\n",
      "Done :  570\n",
      "Done :  571\n",
      "Done :  572\n",
      "Done :  573\n",
      "Done :  574\n",
      "Done :  575\n",
      "Done :  576\n",
      "Done :  577\n",
      "Done :  578\n",
      "Done :  579\n",
      "Done :  580\n",
      "Done :  581\n",
      "Done :  582\n",
      "Done :  583\n",
      "Done :  584\n",
      "Done :  585\n",
      "Done :  586\n",
      "Done :  587\n",
      "Done :  588\n",
      "Done :  589\n",
      "Done :  590\n",
      "Done :  591\n",
      "Done :  592\n",
      "Done :  593\n",
      "Done :  594\n",
      "Done :  595\n",
      "Done :  596\n",
      "Done :  597\n",
      "Done :  598\n",
      "Done :  599\n",
      "Done :  600\n",
      "Done :  601\n",
      "Done :  602\n",
      "Done :  603\n",
      "Done :  604\n",
      "Done :  605\n",
      "Done :  606\n",
      "Done :  607\n",
      "Done :  608\n",
      "Done :  609\n",
      "Done :  610\n",
      "Done :  611\n",
      "Done :  612\n",
      "Done :  613\n",
      "Done :  614\n",
      "Done :  615\n",
      "Done :  616\n",
      "Done :  617\n",
      "Done :  618\n",
      "Done :  619\n",
      "Done :  620\n",
      "Done :  621\n",
      "Done :  622\n",
      "Done :  623\n",
      "Done :  624\n",
      "Done :  625\n",
      "Done :  626\n",
      "Done :  627\n",
      "Done :  628\n",
      "Done :  629\n",
      "Done :  630\n",
      "Done :  631\n",
      "Done :  632\n",
      "Done :  633\n",
      "Done :  634\n",
      "Done :  635\n",
      "Done :  636\n",
      "Done :  637\n",
      "Done :  638\n",
      "Done :  639\n",
      "Done :  640\n",
      "Done :  641\n"
     ]
    }
   ],
   "source": [
    "# Check whether encoding-decoding process is valid\n",
    "idx = 0\n",
    "for string in test_list:\n",
    "    sentence_ids = bpemb_de.encode_ids_with_bos_eos(string)\n",
    "    sentence_vec = bpemb_de.vectors[sentence_ids]\n",
    "    \n",
    "    decoded_ids = find_similar_vec(sentence_vec)\n",
    "    \n",
    "    if decoded_ids.tolist() != sentence_ids:\n",
    "        print(\"Error : \", f'{idx}')\n",
    "    else:\n",
    "        print(\"Done : \", f'{idx}')\n",
    "    idx+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "21_ML",
   "language": "python",
   "name": "21_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
